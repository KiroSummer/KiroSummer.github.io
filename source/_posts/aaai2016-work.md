title: AAAI2016-work
date: 2016-06-13 19:37:57
tags: [work]
---
# AAAI2016工作记录
## Giga数据处理
### 1.利用脚本“convertCONLL2sentence.py”将CONLL格式的Giga数据重新处理成：
> * 一个句子一行的格式
> * 丢弃字的长度大于60的句子
<!--more-->

总共约1181w个句子，丢弃了2,083,300个句子，最后得到9,727,428个句子

### 2.利用脚本“echo\_client.py”将sentence文件利用demo进行分词词性句法分析：
2016-6-13-19-35: 开始利用demo进行处理
2016-6-13-21-33: 处理出来了3w个句子
两个小时处理出来了3w个句子，速度有点慢。
因为速度实在太慢，就不跑了。改用只含有分词的demo进行分词处理：

----
2016-6-14-08:50: 开始利用demo进行分词处理
2016-6-14-09:00: 处理出来了7w个句子
大约估算一下： 1h能够处理42w个句子；1day能够处理1008w个句子；所以1day的时间就可以将全部数据处理完成。

----
Giga数据使用分词demo处理完成，根据概率提取相关句子处理情况如下：（句子总数：9,727,428）
> * 概率小于__0.5__丢弃：1,020,235，提取出：8,707,193
> * 概率小于__0.6__丢弃：2,497,030，提取出：7,230,398
> * 概率小于__0.7__丢弃：3,923,422，提取出：5,804,006<font color=red>丢弃：2,606,785，提取出：7,120,643</font>
> * 概率小于__0.8__丢弃：5,316,614，提取出：4,410,814
> * 概率小于__0.9__丢弃：6,791,494，提取出：2,935,494
结果：使用概率小于0.7的进行处理，也就是句子总数580w<font color=red>712w</font>

#### 处理word embedding
在处理word embedding的过程中，遇到了一些noise，导致处理出来的文件格式不对。
> * ＩＡＭＶＥＲＹＨＡＰＰＹＴＯＪＯＩＮＴＨＥＨＯＵＳＴＯＮＲ
> * ｈｔｔｐ：／／ｗｗｗ．１０ｓｔｃｅｎｔｕｒｙｆｏｒｕ
含有这些noise，需要把这些剔除掉。因此，在我将语料处理成word2vec需要预料的时候，我认为设定将word length > 20的句子给扔掉了。

#### 2.1 比较使用demo分析过的和原先的分词结果的差异：
> * 下面是概率0.7抽取过的和原先数据的对比

|sentence|original|demo|
|--------|--------|----|
|同时增辟新加坡至印尼泗水、安汶和比阿克岛的航线。|比 阿克岛|比阿克岛|
|西安航空发动机公司将航空发动机改型为１０马力工业型燃气轮机，|发动 机改型 马力工业型 燃气轮机|发动机 改型 马力 工业型 燃气 轮机|
|目前，外商投资企业已遍布闽西各县市。|闽 西|闽西|
|卡尔波夫以１０分之差挑战失败。|１０ 分|１０分|
|世界冠军保持者则仍获世界冠军称号|保持 者|保持者|
|联合国近东巴勒斯坦难民救济署调查并向他提供|近 东 救济 署|近东 救济署|
|已经使４２００多名伊拉克人死亡|伊拉克 人|伊拉克人|
|由于交易商们越来越担心海湾随时会爆发战争|交易商们|交易 商们|
|收盘价为每桶２８|收盘 价|收盘价|
|需要全国和睦、民族和解、守纪尽职|和 睦 守纪尽职|和睦 守纪 尽职|
|拉什迪已收到埃及宗教基金部部长穆罕默德|基金 部|基金部|
|阿里？|阿 里|阿里|
|马哈古卜访问开罗的正式邀请，马哈古卜和拉什迪于圣诞节前夜举行了会晤。|马哈 古卜 拉什迪 于|马哈古卜 拉什 迪于|
|强行越境会给他们的生命带来严重后果|越 境|越境|
|据伊朗伊斯兰共和国通讯社报道|伊斯 兰|伊斯兰|

> * 下面是直接demo处理的结果（去除了字>60的句子）和原先的结果对比

|__sentence__|__original__|__demo__|
|------------|------------|--------|
|同时增辟新加坡至印尼泗水、安汶和比阿克岛的航线。|比 阿克岛|比阿克岛|
|满载塔里木原油的第一列火车，|满 载|满载|
|来自塔里木石油勘探开发指挥部轮南试采区|轮南 试采区|轮南试 采区|
|唐山一年新增农村自动电话１０户|１０ 户|１０户|
|新增小程控和电子制式的交换机１０门|新增 小 １０ 门|新 增小 １０门|
|炼油厂在对原油进行催化裂化时|催化 裂化|催化裂化|
|随之产生的干气通常被白白烧掉|随 之|随之|
|西安航空发动机公司将航空发动机改型为１０马力工业型燃气轮机，|发动 机改型 马力工业型 燃气轮机|发动机 改型 马力 工业型 燃气 轮机|
|闽西包括龙岩地区１０县１０市|１０ 县 １０ 市|１０县 １０市|
|闽西还是福建的主要林区，|闽 西|闽西|
|是中国大陆重要的松香、商品原材主产区之一|原材 主产区|原材主 产区|
|松香最高年产达１０吨|最高 年产|最 高 年 产|
|闽西目前正在加强基础设施建设|正在|正 在|
|秦皇岛市坚持“内联外引相结合，以内联促外引”的对外开放取得成绩|内联 外引 相 内联 促外引|内 联外 引相 内 联促 外引|
|这个市办起１０家先内联后外引的“中中外”企业|先内联 后|先 内 联后|
|秦皇岛市开放之初，经济实力比较薄弱，|秦皇岛 市|秦皇岛市|
|先后与２０多个省、市达成１０项横向联合项目|横向|横 向|
|这家工厂采用八十年代世界先进的复合肥生产工艺|复合 肥|复合肥|
|年生产４８万吨磷酸二铵或６０万吨氮磷钾复合肥|二铵 氮磷钾 复|二 铵 氮磷 钾复|
|卡尔波夫以１０分之差挑战失败。|１０ 分 之差|１０分之差|
|卡尔波夫处在明显劣势的情况下，只好同意和棋。|卡尔波夫 处|卡尔波夫处|
|卡斯帕罗夫在本月１０日进行的第２２盘比赛中与卡尔波夫下和后|第２２ 盘 下和|第２ ２盘 下 和|

### 3.利用CNN、LSTM，CTB7数据训练一个模型，进行580w数据的词性标注工作
#### 3.1 CNN模型代码修改完成，能够完成保存模型的相关数据
在CTB7数据集上训练一个模型，最好的结果如下：

|__epoch__|__dev__|__test__|
|---------|-------|--------|
|4        |94.09% |93.83%  |
ps: epoch从0开始。
为了测试模型是否，正确，使用CTB7数据集的test再单独测试一下，结果如下：（模型使用的word embedding就是单纯的从上述训练过程保存下来的，不含有Giga的，是经过train提取过得）
__93.83%__
使用该模型处理Giga 580w数据
#### 3.2 LSTM模型代码修改完成，能够保存模型以及进行单独load模型进行相关的测试
在CTB7数据集上训练一个模型，最好的结果如下：

|__epoch__|__dev__|__test__|
|---------|-------|--------|
|6        |94.80% |94.59%  |
ps: epoch从0开始
同样的，使用test数据进行load model的测试，结果相同
使用该模型处理Giga 580w数据，数据处理成功！
时间统计：
2016-6-24-16:29 开始处理前10000条数据
2016-6-24-16:32 10000条数据处理结束
计算一下：1w条数据3min，那么580w条数据应该需要1740min=__29h__
#### 上面的实验是在提供了word embedding的情况，下面的小节提供了不使用word embedding的情况。(2016-6-28-午后 更)
在不使用word embedding的情况下，随机初始化生成word embedding，我们得到了一下准确率：

|__dev__|__test__|
|-------|--------|
|94.50% |94.33%  |
在第5次迭代，迭代从0开始

### 4.利用berkeley parser & CTB7训练得到的Grammer，对580w数据进行分析处理：
写了一个简单的脚本"converCONLL2sentence.py"，将580w的CONLL格式文件转换成words文件：一行一个句子，以空格分割单词
2016-6-15-22-37: 开始处理demo_Giga.words
2016-6-15-22-57: 处理了8357个句子
大约估算一下：20min处理了8357个句子，1h能够处理25,071个句子。1day能够处理601,704个句子。对于目标5,804,006个句子远远是不行的。

----
发现在跑程序的过程中，CPU一直都是100%；后来查找相关资料发现，需要设置一个参数__-nThreads 10__，ok，解决问题：
2016-6-16-09-39: 开始处理demo_Giga.words
2016-6-15-10-36: 处理了144557个句子
大约估算一下：1h处理14w个句子。1day能够处理336w的数据，所以1个大半天就能够处理完580w的数据。__YES__

处理完成之后的数据保存在如下位置：
qrxia@192.168.131.173:~/work/coling2016/berkeley-parser/Giga/Giga_berkeley.conll

### 5.利用CRF(wspos-tagger)训练一个词性标注模型(CTB7数据集)，在dev/test上得到结果(1-best tags, pruning)
进行pruning的时候，相关参数设置如下：
```
test-tag-filter=1
test-tag-filter-lambda=0.01
```
项目工程在*m173 ~/wspos-tagger/example-ctb7-convertedPD-wspos/coling2016*，将相关的词性标注准确率记录如下：

|__dev__|__test__|
|-------|--------|
|94.45% |94.21%  |
相关的输出文件和概率文件也在相同的目录下。

#### 利用训练好的CRF模型对提取过的Giga.conll数据进行词性标注：
同样利用第5节的pos工程，对Giga.conll进行处理。(1-best tags, pruning)

将相关的输出文件保存如下位置：
*m173 ~/wspos-tagger/example-ctb7-convertedPD-wspos/crf_Giga*

### 6.将LSTM，CRF，Berkeley模型在CTB7上面的dev数据集结果进行相互比较
|__gold__/__sys__|__berkeley(dev/test)__|__crf(dev/test)__|__lstm(dev/test)__|
|----------------|----------------------|-----------------|------------------|
|__berkeley__    |×                     |93.59%/93.47%	  |93.82%/93.70%	 |
|__crf__         |× 					|×				  |95.52%/95.24%	 |
|__lstm__        |× 					|×  			  |×				 |
|__gold__        |93.98%/93.76%			|94.49%/94.22%    |94.80%/94.59%	 |

#### 句法的结果(no-punc)在Berkeley模型上
|       |__dev/test__   |
|-------|---------------|
|__UAS__|82.53%/83.24%  |
|__LAS__|77.78%/78.27%  |

### 7.使用berkeley产生的数据，LSTM、CRF再处理Giga
因为在berkeley模型的测试过程中，有某些数据被舍弃掉了。为了方便后面的数据处理工作，以后统一使用berkeley模型产生的数据
现将最终生成的数据的路径记录如下：

|__data name__|__path__|
|-------------|--------|
|lstm\_Giga.conll|171:~/LSTMPOSTagging/Giga/lstm\_Giga.conll.conll|
|crf\_Giga.conll|173:~/wspos-tagger/example-ctb7-convertedPD-wspos/crf\_Giga/Giga\_crf.conll|
|berkeley\_Giga.conll|173:~/work/coling2016/berkeley-parser/Giga/Giga\_berkeley.conll|

将lstm和berkeley处理完成的Giga处理成partial和ambiguous格式的，完成，在一下路径：
173:~/data/coling2016/ambiguous\_Giga.conll
173:~/data/coling2016/partial\_Giga.conll
### 8.分别使用lstm+berkeley, lstm&berkeley, lstm, berkeley, crf的几个Giga数据在CRF-pos-tagger代码上训练模型
因为linux系统中文件名不能使用'&'，所以使用\_and\_代替，即lstm\_and\_berkeley
#### 8.1 CRF-pos-tagger模型，lstm\_and\_berkeley作为train2
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|
|------------------|----------------------------|------------------------------------------|
|2016-6-29 09:53:51|32                          |94.57%                                    |
|2016-6-30 09:24:25|64/71                       |94.74%/94.70%                             |
|2016-7-01 09:05:37|94/105                      |94.77%/94.70%                             |
|2016-7-01 21:49:51|94/125                      |94.77%/94.66%                             |
over!
#### 8.2 CRF-pos-tagger模型，lstm+berkeley作为train2
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|
|------------------|----------------------------|------------------------------------------|
|2016-6-29 09:36:54|32                          |94.56%                                    |
|2016-6-30 08:54:01|64/72                       |94.77%/94.70%                             |
|2016-7-01 01:32:58|64/95                       |94.77%/94.72%                             |
over!
#### 8.3 CRF-pos-tagger模型，giga\_crf作为train2
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|
|------------------|----------------------------|------------------------------------------|
|2016-6-29 10:13:47|33                          |94.37%                                    |
|2016-6-30 09:03:35|50/72                       |94.50%/94.49%                             |
|2016-7-01 09:30:00|95/106                      |94.53%/94.52%                             |
|2016-7-01 22:33:16|95/126                      |94.53%/94.42%                             |
over!
#### 8.4 CRF-pos-tagger模型，giga\_lstm作为train2
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|
|------------------|----------------------------|------------------------------------------|
|2016-6-29 10:24:20|33                          |94.45%                                    |
|2016-6-30 09:13:19|64/71                       |94.65%/94.60%                             |
|2016-7-01 09:07:39|94/104                      |94.66%/94.51%                             |
|2016-7-02 08:33:45|122/142                     |94.66%/94.56%                             |
|2016-7-03 08:25:31|147/173                     |94.67%/94.60%                             |
|2016-7-03 12:25:31|147/178                     |94.67%/94.55%                             |
over!
#### 8.5 CRF-pos-tagger模型，giga\_berkeley作为train2
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|
|------------------|----------------------------|------------------------------------------|
|2016-6-29 10:32:57|32                          |94.14%                                    |
|2016-6-30 09:20:32|50/70                       |94.35%/93.91%                             |
|2016-6-30 16:02:06|50/81                       |94.35%/94.17%                             |
over!

### 9.训练3个joint模型
#### 9.1 ctb7-2osib
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|__best / current UAS__|__best / current LAS__|
|------------------|----------------------------|------------------------------------------|----------------------|----------------------|
|2016-7-02 23:38:13|1                           |94.83%                                    |81.34%                |×                     |
|2016-7-03 11:29:55|2                           |95.10%                                    |82.22%                |                      |
|2016-7-03 21:46:28|3                           |95.21%                                    |82.59%                |                      |
|2016-7-04 07:41:45|4                           |95.26%                                    |82.61%                |                      |
|2016-7-04 18:35:29|5                           |95.31%                                    |82.64%                |                      |
|2016-7-05 06:04:14|6                           |95.31%/95.29%                             |82.65%                |                      |
|2016-7-05 18:11:15|7                           |95.35%                                    |82.65%/82.61%         |                      |
|2016-7-06 07:48:12|8                           |95.35%/95.34%                             |82.65%/82.55%         |                      |
|2016-7-06 20:38:22|9                           |95.35%                                    |82.65%/82.64%         |                      |
|2016-7-07 10:25:55|10                          |95.35%/95.34%                             |82.72%                |                      |
|2016-7-08 01:46:23|11                          |95.35%/95.32%                             |82.72%/82.71%         |                      |
|2016-7-08 17:21:23|12 							|95.35%/95.30%							   |82.75%                |						 |
|2016-7-09 08:39:23|13                          |95.35%/95.28%							   |82.75%/82.73%		  |						 |
|2016-7-09 22:16:40|14                          |95.35%/95.28%							   |82.75%/82.69%		  |						 |
|2016-7-10 11:02:20|15                          |95.35%/95.25%							   |82.75%/82.72%		  |						 |
|2016-7-10 22:02:48|16 							|95.35%/95.23%							   |82.75%/82.68%		  |						 |
|2016-7-11 09:32:17|17                          |95.35%/95.20%                             |82.75%/82.61%         |                      |
|2016-7-11 22:04:32|18                          |95.35%/95.18%                             |82.75%/82.60%         |                      |
over
#### 9.2 ctb7-2osib-labeled
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|__best / current UAS__|__best / current LAS__|
|------------------|----------------------------|------------------------------------------|----------------------|----------------------|
|2016-6-29 13:05:45|1                           |95.02%                                    |81.93%                |77.44%                |
|2016-6-30 14:26:31|2                           |95.10%                                    |82.51%                |78.10%                |
|2016-7-01 16:17:27|3                           |95.12%                                    |82.89%                |78.46%                |
|2016-7-03 08:56:28|4                           |95.16%                                    |83.07%                |78.64%                |
|2016-7-04 13:40:40|5                           |95.19%                                    |83.13%                |78.69%                |
|2016-7-06 00:09:14|6                           |95.23%                                    |83.28%                |78.82%                |
|2016-7-07 14:16:57|7                           |95.26%                                    |83.28%/83.16%         |78.82%/78.71%         |
|2016-7-09 10:10:25|8                           |95.30%                                    |83.28%/83.21%         |78.82%/78.76%         |
|2016-7-10 20:49:07|9                           |95.30%/95.29%							   |83.28%/83.19%	 	  |78.82%/78.74%         |
|2016-7-12 06:19:40|10                          |95.30%/95.29%                             |83.28%/83.26%         |78.82%/78.79%		 |
|2016-7-13 04:51:18|11                          |95.30%/95.29%                             |83.28%/83.18%         |78.82%/78.70%         |
|2016-7-14 04:32:39|12                          |95.30%                                    |83.28%/83.19%         |78.82%/78.69%         |
|2016-7-15 07:55:15|13                          |95.32%                                    |83.28%/83.17%         |78.82%/78.66%         |
|2016-7-16 14:15:32|14                          |95.33%                                    |83.28%/83.16%         |78.82%/78.65%         |
over! kill
#### 9.3 ctb7-2ocarreras
|__time__          |__best epoch/current epoch__|__best dev accuracy/current dev accuracy__|__best / current UAS__|__best / current LAS__|
|------------------|----------------------------|------------------------------------------|----------------------|----------------------|
|2016-7-04 02:42:53|1                           |95.01%                                    |82.08%                |                      |
|2016-7-05 18:55:40|2                           |95.23%                                    |83.09%                |                      |
|2016-7-07 20:32:05|3                           |95.35%                                    |83.44%                |                      |
|2016-7-10 00:57:01|4						    |95.36% 								   |83.59%				  |						 |
|2016-7-11 19:11:24|5                           |95.42%                                    |83.72%                |                      |
|2016-7-13 03:33:04|6                           |95.42%/95.41%                             |83.78%                |                      |
|2016-7-14 11:35:48|7                           |95.43%                                    |83.85%                |                      |
|2016-7-15 22:45:17|8                           |95.43%                                    |83.86%                |                      |
|2016-7-17 14:02:48|9                           |95.44%                                    |83.94%                |                      |
|2016-7-19 14:08:43|10                          |95.45%                                    |83.95%                |                      |
|2016-7-21 02:44:40|11                          |95.45%/95.44%                             |83.95%/83.87%         |                      |
|2016-7-22 22:06:53|12                          |95.45%/95.41%                             |83.95%/83.89%         |                      |
|2016-7-24 07:51:53|13                          |95.45%/95.40%                             |83.95%/83.90%         |                      |
|2016-7-25 10:46:44|14                          |95.45%/95.38%							   |83.95%/83.80%		  |						 |
|2016-7-26 13:56:51|15                          |95.45%/95.40%                             |83.95%/83.84%         |                      |
|2016-7-27 19:30:15|16                          |95.45%/95.39%                             |83.95%/83.81%         |                      |
|2016-7-29 04:43:03|17                          |95.45%/95.37%                             |83.95%/83.76%         |					     |
### 10.使用joint模型处理Giga(580w)数据
#### 10.1 使用2osib-labeled joint模型处理由CRF处理出来的数据Giga\_crf.conll
开始时间: 2016-7-16 21:49:43
结束时间: 2016-7-16 21:55:28
1w句处理完成，大约估算一下：1w句话，6min；总共__580w__句子，大约需要__58h__。
其中，处理的样例结果如下，第4列(0列开始)是berkeley的处理结果。
```text
1       新加坡  _       NR      NR      _       2       nn      _       NR
2       交通部  _       NN      NN      _       3       nsubj   _       NN
3       说      _       VV      VV      _       0       root    _       VV
4       ，      _       PU      PU      _       3       punct   _       PU
5       近      _       JJ      AD      _       6       amod    _       AD_JJ_VA
6       些      _       M       CD      _       7       clf     _       M_CD
7       年      _       NN      M       _       8       lobj    _       NN_M
8       来      _       LC      LC      _       14      loc     _       LC
9       两      _       CD      CD      _       10      nummod  _       CD
10      国      _       NN      NN      _       12      nn      _       NN
11      空中    _       NN      NN      _       12      nn      _       NN
```
2016-7-19 11:28:39 处理完成！位于172::~/work/coling2016/joint/lgdpj-r42-to-kiro-2016-6-27/ctb7-2osib-labeled/Giga\_joint.conll
#### 10.2 利用joint模型对Giga数据的处理结果跑5个实验
使用wspos-tagger模型
> * CTB7+Giga\_joint
> * CTB7+(Giga\_joint+LSTM)
> * CTB7+(Giga\_joint&LSTM)
> * CTB7+(Giga\_joint+LSTM+Berkeley)
> * CTB7+(Giga\_joint&LSTM&Berkeley)
数据的构成方式如下：
前面几列是joint模型输出的Giga数据，最后一列由__lstm+berkeley+joint__构成。其中，&的方式不重要，因为不相同的词性都会变成'\_'；+的方式严格按照上述的数据顺序构成。
忘记设置"*constrained-tag-train2=1*"，重来！

|__epoch__|__CTB7+Giga\_joint__|__Giga\_joint+LSTM__|__Giga\_joint&LSTM__|__Giga\_joint+LSTM+Berkeley__|__Giga\_joint&LSTM&Berkeley__|
|---------|--------------------|--------------------|--------------------|-----------------------------|-----------------------------|
|1        |91.67%              |91.18%              |91.10%              |91.13%                       |91.05%                       |
|17       |94.27%              |94.33%              |94.30%              |94.32%                       |94.26%                       |
|40       |94.52%              |94.66%              |94.66%              |94.66%                       |94.68%                       |
|over!    |94.70%/123          |94.73%/80           |94.75%/80           |94.78%/80                    |94.77%/80                    |
