title: conditional random field学习总结
date: 2016-5-18 19:39:34
tags: [机器学习, CRF]
---
# 概述
CRF(条件随机域)是用来处理结构化分类问题的，我学习它是用来处理词性标注问题的。
[我学习CRF的讲义](http://hlt.suda.edu.cn/~zhli/teach/cip-2015-fall/12-crf/main.pdf)
# 实验结果
|__epoch__|__best accuracy__|
|---------|-----------------|
|94.45%   |18               |
[log文件](/documents/crf/log.txt)
<!--more-->
# 使用训练好的模型测试test
因为此次实验是选取dev最好的情况的模型进行test测试，故而此处的准确率dev和test合起来写

|__epoch__|__Accuracy(dev/test)__|
|---------|----------------------|
|18       |94.45%/94.20%         |
[log文件](/documents/crf/log_test.txt)
## Bug记录
我觉的有必要把我遇到的bug记录下来，因为此次调试bug的时间太长了，有自己理解不清的原因，也有自己写代码疏忽造成的bug。
### bug1
```
	sentence  1
	1035.3561795 1035.3561795 1036.3561795
	a ---> end == b ---> start
	sentence  2
	1260.5454322 1260.5454322 1261.5454322
	a ---> end == b ---> start
	sentence  3
	1702.74797929 1702.74797929 1703.74797929
	a ---> end == b ---> start
	sentence  4
	-1416.74092483 -1416.74092483 -1415.74092483
	a ---> end == b ---> start
	sentence  5
	-6589.70608716 -6589.70608716 -6588.70608716
	a ---> end == b ---> start
	sentence  6
	-14067.2452692 -14067.2452692 -14066.2452692
	a ---> end == b ---> start
	sentence  7
	-16107.5039593 -16107.5039593 -16106.5039593
```
如上所示，三个数字分别表示为：\\(\alpha(sentence\\_length, STOP)\\), \\(\beta(-1, START)\\)，\\(\Sigma_t\\)我们可以看出来，前面两个得分前向和后向是相等的，但是最后一个前向和后向相乘的得分比前面两个得分多了一个1.0，这个是很诧异的一件事情。还有就是得分之和越来越小，可能是因为跟新gradient的时候出了问题。
*多了一个1.0的原因*
因为我默认a(-1, START) = 1， b(sentence\_length, STOP) = 1，但是 t in T a(k, t)\*b(k, t)加了两遍1，所以回比a和b的得分多一个1。应该是a(-1, START) = 0， b(sentence\_length, STOP) = 0。

### bug2
```
	i =  1 tag_i ==  VA
	20.8763772626
	[0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735, 0.9941132029796735]
```
为什么我的概率p那么大？
*原因*
因为加了log处理数据，防止数据的溢出，然后我概率公式就应该要有相应的变化：
本来的p(i, ti\_left, ti | S) = (a(i - 1, ti\_left)) * e \*\* Score(S, i, ti\_left, ti) * b(i, ti) / Z(S)需要做相应的变化，简单而言，描述如下：
e \*\* log(a/b) = a/b = e \*\* (log(a) - log(b))
公式作如上变化，就好了
### bug3
从下面的词性序列当中（前面一个是正确的序列，后面一个是Viterbi得到的序列），我们可以明确的看到，好像后面得到的词性篡位了！因为Viterbi是经过global linear model检验过得、只修改了一点点，所以我对这个不作多少怀疑，看看更新权重的模块有没有出现什么样子的问题。
```
	['NR', 'NN', 'NN', 'CC', 'NR', 'NN', 'VV', 'NN'] ['NR', 'NN', 'CC', 'NR', 'NN', 'CC', 'NR', 'NN']
```
### bug4内存泄露
终于找到内存泄露的问题了
```
	self.w = [x + y for x, y in zip(self.w, self.g)]
```
就是这一句话，导致我的内存不断升高，注释掉就好了。那么为什么会这样呢？
暂时的解决方案：
```
	import gc
	gc.disable()
	......
	gc.enable()
```
暂时只能压住内存上涨的势头，但是仍会多出一些内存！很奇怪，以前的一些model怎么没有发现类似的问题的？！回头我再查查！

